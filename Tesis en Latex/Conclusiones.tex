\chapter*{Conclusiones generales}

Los resultados de este trabajo han sido satisfactorios y cumplen con los objetivos propuestos para solucionar la problem\'{a}tica establecida. Estos junto a sus correspondientes respaldos investigativos, demouestran que los modelos DL poseen un gran resultado en la detecci\'{o}n de anomal\'{i}as, y a su vez, en la detecci\'{o}n de fraude en tarjetas de cr\'{e}dito. Son adem\'{a}s, la mejor opci\'{o}n cuando se trata de trabajar con \textit{Big Data}, ya que los modelos ML pierden efectividad cuando aumenta el c\'{u}mulo de datos que procesa en la detecci\'{o}, creando un sobre-entrenamiento del modelo. El sobre-entrenamiento tambi\'{e}n puede afectar a los modelos DL, pero en este caso es solucionable con el correcto ajuste de los par\'{a}metros, lo que es una de las otras grandes ventajas de estos modelos. Tambi\'{e}n son personalizables, esto se debe a que se le pueden cambiar la cantidad y el tipo de capas que se utilizan para la clasificaci\'{o}n, incluso la cantidad de neuronas que posee cada capa. Mediante la experimentaci\'{o}n se han podido obtener grandes resultados, los cuales evidencian una gran superioridad de los modelos DL con respecto a los modelos ML. A continuaci\'{o}n los principales resultados que se obtuvieron:

\begin{itemize}
	\item El modelo CNN obtiene mejores resultados con los datos desbalanceados, siendo el m\'{a}s efectivo en la detecci\'{o}n de fraude de tarjeta de cr\'{e}dito cuando existe desbalance de la informaci\'{o}n.
	\item El modelo BPNN obtiene los mejores resultados en cuanto a las estrategias aplicadas para solucionar el desbalance de la informaci\'{o}n, a pesar de obtener resultados id\'{e}nticos con los modelos AE, DAE, RNN y LSTM, este posee mayor precisi\'{o}n.
	\item En los modelos AE, DAE, RNN y LSTM, se aprecian igualdad en los resultados en cuanto a las pruebas, sin embargo su gran diferencia se puede observar en el entrenamiento de los mismos.
	\item En cuanto a la divisi\'{o}n del conjunto de datos, se aprecia que a medida que aumenta el porcentaje de datos para el entrenamiento, mejoran los resultados de \textit{F1 Score}, pero a su vez disminuye la precisi\'{o}n con que se detectan los fraudes. Es por ello es importante encontrar un procentaje donde ambas m\'{e}tricas se encuentren equilibradas.
	\item El \textit{overfitting} afecta tambi\'{e}n a los modelos DL por lo que es necesario aplicar el \textit{dropout regularization}, de esta forma se reajusta el modelo.
	\item \textit{Random Forest} result\'{o} como el mejor modelo dentro de los modelos ML, obteniendo los mejores resultados en las m\'{e}tricas de estudio.
\end{itemize}

Los resultados obtenidos en la experimentaci\'{o}n definieron las bases para el desarrollo de una librer\'{i}a Python, la cual nos permite ajustar par\'{a}metros de los modelos. Esta librer\'{i}a es un proycto en desarrollo, acutalmente solo es ajustable el orden de los \textit{dropouts} y la cantidad de \textit{epochs}. Actualmente la librer\'{i}a permite el uso de los modelos ML y DL utilizados en la experimentaci\'{o}n.
